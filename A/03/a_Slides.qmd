---
format: 
  revealjs:
    css: ../../styles.css
    slide-number: true
    show-slide-number: all
    preview-links: false
    progress: true
    history: true
    hash-type: number
    theme: default
    code-block-background: true
    highlight-style: zenburn
    code-link: false
    code-copy: true
    code-line-numbers: false
    controls: true
    pagetitle: "Multilevel Modeling"
    author-meta: "Jeffrey Girard"
    semester: "Spring 2026"
    course: "PSYC 894"
    lecture: "03a"
execute:
  echo: true
  eval: true
  collapse: false
  cache: false
---

::: {.my-title}
# [Multilevel Modeling]{.blue}
Issues with Clustered Data

::: {.my-grey}
[{{< meta semester >}} | CLAS | {{< meta course >}}]{}<br />
[Jeffrey M. Girard | Lecture {{< meta lecture >}}]{}
:::

![](../../img/city-girl.svg){.absolute bottom=30 right=0 width="400"}
:::

## Roadmap

::: {.columns .pv4}

::: {.column width="60%"}
1. Multilevel Data and Questions
  
2. Conceptual Issues with Clustering

3. Statistical Issues with Clustering
:::

::: {.column .tc .pv4 width="40%"}
{{< lif "../../icons/map.json" trigger=hover colors=secondary:#2a76dd class=rc >}}
:::

:::


# Multilevel Data and Multilevel Questions

## What is multilevel data? {.smaller}

- Data are [hierarchically clustered]{.b .blue} when there are groups of observations<br> that are more similar *within* groups than they are *between* groups
    + We say that observations are **nested within** clusters
    + We count the levels (L\#) in ascending order of nesting
    + *e.g., students (L1) within classrooms (L2)... within schools (L3)...*
    + *e.g., days (L1) within participants (L2)... within countries (L3)...*

::: {.fragment}
- In MLM, we assume a [successive sampling]{.b .green} strategy
    + Specifically, we randomly sample from the top-down
    + *e.g., we sample classrooms and then students within each classroom*
    + *e.g., we sample participants and then days within each participant*

:::

## What is and isn't a cluster? {.smaller}

::: {.columns}
::: {.column width="50%"}
[Random Clusters...]{.b .blue}

- Are **randomly sampled**
- Come from a **population**
- Are **interchangeable**
- Are not exhaustive
- Permit **generalization**
- Require a **large number**

:::{.fragment}
- *e.g., classrooms*
- *e.g., individuals*

:::
:::
::: {.column width="50%"}

[Fixed Groups...]{.b .green}

- Are not randomly sampled
- Do not come from a population
- Are not interchangeable
- Are (typically) **exhaustive**
- Do not permit generalization
- Do not require a large number

::: {.fragment}
- *e.g., biological sexes*
- *e.g., experimental conditions*
:::
:::
:::

## Types of Multilevel Variables {.smaller}

- [Global]{.b .blue} variables describe their own level
    + *e.g., the **motivation** of a student (L1) or the **size** of a class (L2)*
    + *e.g., the **stress level** of a day (L1) or the **gender** of a participant (L2)*

::: {.fragment}
- [Structural]{.b .green} variables "aggregate up" from a lower-level
    + *e.g., the **average motivation** of a class (L2), aggregated up from students (L1)*
    + *e.g., the **average stress level** of a participant (L2), aggregated up from days (L1)*

:::

::: {.fragment}
- [Disaggregated]{.b .red} variables "copy down" from a higher-level
    + *e.g., the **classroom size** of a student (L1), copied down from class (L2)*
    + *e.g., the **gender** of a day (L1), copied down from participant (L2)*
    + *Note: This is often how Global (L2) variables are stored in "long format" data.*

:::

## Practice: Classify that Variable {.smaller}

**Scenario:** We are studying **employees (L1)** nested within **companies (L2)**.

For each variable below, is it **Global**, **Structural**, or **Disaggregated**?

::: {.incremental}
1. **"Employee Job Satisfaction"**
    - [Answer:]{.blue} **Global**
    - *It describes the specific level (L1) at which it was measured.*

2. **"Company Profit"** (assigned to every employee row)
    - [Answer:]{.red} **Disaggregated**
    - *It describes the higher level (L2) but is "copied down" to the lower level (L1).*

3. **"Average Employee Satisfaction"** (calculated for each company)
    - [Answer:]{.green} **Structural**
    - *It describes the higher level (L2) but is "aggregated up" from the lower level (L1).*
:::

## Multilevel Research Questions {.smaller}

- [Within-Cluster]{.b .blue} Questions
    + *e.g., how does student motivation (L1) relate to student achievement (L1)?*
    + *e.g., how does daily stress (L1) relate to daily calorie intake (L1)?*

:::{.fragment}
- [Between-Cluster]{.b .green} Questions
    + *e.g., how does average motivation (L2) relate to average achievement (L2)?*
    + *e.g., how does participant gender (L2) relate to average calorie intake (L2)?*

:::

:::{.fragment}
- [Cross-level]{.b .red} Questions
    + *e.g., does the relationship between a student's motivation (L1) and achievement (L1) depend on the class's average motivation (L2)?*
    + *e.g., does the relationship between daily stress (L1) and daily calorie intake (L1) depend on the participant's gender (L2)?*

:::


## Brief Activity {background-color="#34495e"}

::: {.incremental .white-text}
1. How might data you care about be **clustered**? 
    + *What are the clusters, levels, and level numbers?*
2. What are some **multilevel variables** you care about?
    + *What level is each variable on? What type is each?*
3. What are some **multilevel questions** you care about?
    + *Is each within-cluster, between-cluster, or cross-level?*
    
:::


# Conceptual Issues

## Simpson's Paradox

> Individuals who engage in more rigorous physical activity generally have a *lower* average resting heart rate. However, in the moment, engaging in more rigorous physical activity temporarily *increases* heart rate.

:::{.callout-important title="Caution" .fragment .pv4}
- Relationships may actually reverse at different levels
:::

## Visualizing the Paradox {.smaller}

```{r}
#| echo: false
#| message: false
#| fig-align: center
#| fig-height: 5

library(ggplot2)
library(dplyr)

# Synthetic data generation for Simpson's Paradox
set.seed(123)
n_groups <- 5
n_per_group <- 20
df_simpson <- tibble(
  group = rep(1:n_groups, each = n_per_group),
  # Between effect: As group X increases, group Y decreases
  x_between = rep(seq(10, 50, length.out = n_groups), each = n_per_group),
  y_between = -0.5 * x_between, 
  # Within effect: As individual x increases, individual y increases
  x_within = rnorm(n_groups * n_per_group, 0, 3),
  y_within = 0.8 * x_within + rnorm(n_groups * n_per_group, 0, 2),
  # Combined
  x = x_between + x_within,
  y = y_between + y_within
)

ggplot(df_simpson, aes(x, y)) +
  geom_point(aes(color = as.factor(group)), alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed") + # Naive fit
  geom_smooth(aes(group = group, color = as.factor(group)), method = "lm", se = FALSE) + # Cluster fit
  annotate("text", x = 40, y = -5, label = "Naive Global Fit (Negative)", fontface = "italic") +
  theme_minimal(base_size = 20) +
  theme(legend.position = "none") +
  labs(x = "Physical Activity", y = "Heart Rate", title = "Within (Positive) vs. Between (Negative)")
```

## The Ecological Fallacy

> Wealthier countries tend to have *higher* average happiness levels. However, this does not necessarily imply that, within a given country, wealthier individuals tend to be happier. In fact, this effect tends to be much *weaker.*

:::{.callout-important title="Caution" .fragment}
- Higher-level results may not apply to lower levels
:::

## The Atomistic Fallacy

> Wealthier individuals in the USA tend to vote more conservatively. However, this does not necessarily imply that wealthier regions also tend to vote more conservatively. In fact, the opposite is true with US states and counties tending to vote more liberally.

:::{.callout-important title="Caution" .fragment}
- Lower-level results may not apply to higher levels
:::

## Lurking Moderators

> A new treatment may work (or not work) in a given hospital. However, this does not necessarily imply that it would also work (or not work) in all hospitals. There may be other hospital-level moderators at play (e.g., due to different staff, patients, and environmental factors).

:::{.callout-important title="Caution" .fragment}
- A lower-level effect may only be present in certain clusters
:::

# Statistical Issues

## Forcing a Single Level {.smaller}

- If we [disaggregate to the lowest level]{.b .blue} and run a single-level model...
    + We treat 10 students in 20 classrooms as 200 IID students
    + Standard errors will be too low and power will be too high
    + We will increase our Type I Error rate (false positives)
    + We may commit the atomistic fallacy (if actually interested in L2)

:::{.fragment}
- If we [aggregate to the highest level]{.b .green} and run a single-level model...
    + We treat 10 students in 20 classrooms as 20 IID classrooms
    + Standard errors will be okay but power will be too low
    + We will increase our Type II Error rate (false negatives)
    + We may commit the ecological fallacy (if actually interested in L1)
    
:::

:::{.fragment}
- In neither case can we explore [cross-level research questions]{.b .red}

:::

## The Danger of Ignoring Clustering {.smaller}

**Simulation:** We simulate 500 datasets where **no effect exists** ($\beta=0$). We analyze *the exact same data* two ways: ignoring clustering (LM) and accounting for it (MLM). Because H0 is true, only ~5\% of slope p-values should be $<.05$. This is true for MLM but not for LM.

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 10
#| fig-height: 5
#| message: false
#| warning: false

library(ggplot2)
library(dplyr)
library(lme4)
library(parameters) # from easystats
library(tidyr)

set.seed(2026)
n_reps <- 500

sim_results <- replicate(n_reps, {
  n_groups <- 20
  n_per_group <- 30
  group_x <- rnorm(n_groups) 
  group_int <- rnorm(n_groups)
  df <- tibble(
    group = rep(1:n_groups, each = n_per_group),
    x = rep(group_x, each = n_per_group),
    y = rep(group_int, each = n_per_group) + rnorm(n_groups * n_per_group)
  )
  m_bad <- lm(y ~ x, data = df)
  p_bad <- p_value(m_bad)$p[2]
  m_good <- lmer(y ~ x + (1|group), data = df)
  p_good <- p_value(m_good)$p[2]
  c(lm = p_bad, lmer = p_good)
})

# 1. Calculate the exact percentages
pct_lm <- mean(sim_results["lm", ] < .05) * 100
pct_mlm <- mean(sim_results["lmer", ] < .05) * 100

# 2. Create dynamic labels
lab_lm <- sprintf("LM (%.1f%% < .05)", pct_lm)
lab_mlm <- sprintf("MLM (%.1f%% < .05)", pct_mlm)

sim_df <- 
  t(sim_results) |> 
  as_tibble() |> 
  pivot_longer(
    cols = everything(), 
    names_to = "Model", 
    values_to = "p_value"
  ) |> 
  mutate(
    Model = factor(
      Model,
      levels = c("lm", "lmer"), 
      labels = c(lab_lm, lab_mlm)
    )
  )

# Plot
ggplot(sim_df, aes(x = p_value, fill = Model)) +
  geom_histogram(breaks = seq(0, 1, 0.05), color = "white", alpha = 0.8) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  scale_fill_manual(values = c("#cc0000", "#137752")) +
  facet_wrap(~Model) +
  labs(
    x = "p-Value", 
    y = "Frequency"
  ) +
  theme_minimal(base_size = 20) +
  theme(
    legend.position = "none",
    strip.text = element_text(face = "bold", size = 24)
  )
```

## Why is the SE too low? {.smaller}

- If we disaggregate to the lowest level, $N$ will be too high
    + We are pretending that we have 200 IID observations
    + But if observations from the same cluster are identical...
    + ...then we really only have 20 unique observations
    + We are taking credit for unique data we don't have
    + This will give us too much confidence (SEs will be too low)
    
:::{.fragment}
- In reality, observations are rarely *identical* within clusters
    + Clustering is rarely perfect, but it likely has *some* influence
    + Our [effective sample size]{.b .blue} is somewhere between 20 and 200
    + Our standard errors should thus be increased by some factor

:::


## Why does getting N right matter?

$$
SE_{\beta_p}=\frac{SD_Y}{SD_{X_p}} \sqrt{\frac{1-R^2}{(n-k-1)(1-R_p^2)}}
$$

:::{.tc .f1}
$n$ is the sample size (assuming IID)<br>
$k$ is the number of predictor ($X$) variables<br>
$R^2$ is the variance in $Y$ explained by all $X$<br>
$R_p^2$ is the variance in $X_p$ explained by all other $X$

:::

:::{.callout-important title="Warning" .fragment}
If $n$ is too large, then $SE_{\beta_p}$ will be too small.
:::

## The Intraclass Correlation (ICC)

- How strong is the clustering or interdependency?
- How correlated are observations from the same cluster?

$$
ICC = \rho = \frac{\tau_{00}^2}{\tau_{00}^2+\sigma^2}
$$

::: {.fsmaller}
- $\sigma^2$ is the **Within-Cluster Variance** (Residual Variance)
- $\tau_{00}^2$ is the **Between-Cluster Variance** (Intercept Variance)
- *Note: `easystats` usually reports the SDs ($\sigma$ and $\tau_{00}$), so you must square them to get the variances for this formula.*
:::

- Ranges from 0 (no clustering) to 1 (perfect clustering)

## Visualizing the ICC

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 10
#| fig-height: 5

library(patchwork)

# Function to generate data with specific ICC
gen_icc_data <- function(n_groups = 10, n_per_group = 10, icc = 0.1) {
  sigma_between <- sqrt(icc)
  sigma_within <- sqrt(1 - icc)
  
  tibble(
    group = rep(1:n_groups, each = n_per_group),
    intercept = rep(rnorm(n_groups, 0, sigma_between), each = n_per_group),
    y = intercept + rnorm(n_groups * n_per_group, 0, sigma_within),
    x = rep(1:n_groups, each = n_per_group) 
  )
}

set.seed(42)
p1 <- gen_icc_data(icc = 0.05) %>%
  ggplot(aes(x = factor(group), y = y, color = factor(group))) +
  geom_point(alpha = 0.6, size = 3) +
  theme_minimal(base_size = 20) + theme(legend.position = "none", axis.text.x=element_blank()) +
  labs(title = "ICC=0.05", x = "Clusters")

p2 <- gen_icc_data(icc = 0.50) %>%
  ggplot(aes(x = factor(group), y = y, color = factor(group))) +
  geom_point(alpha = 0.6, size = 3) +
  theme_minimal(base_size = 20) + theme(legend.position = "none", axis.text.x=element_blank()) +
  labs(title = "ICC=0.50", y = NULL, x = "Clusters")

p3 <- gen_icc_data(icc = 0.95) %>%
  ggplot(aes(x = factor(group), y = y, color = factor(group))) +
  geom_point(alpha = 0.6, size = 3) +
  theme_minimal(base_size = 20) + theme(legend.position = "none", axis.text.x=element_blank()) +
  labs(title = "ICC=0.95", y = NULL, x = "Clusters")

p1 + p2 + p3
```

## Design Effect

- The [design effect]{.b .blue} (DEFF) is a ratio of the sampling variability observed to that expected from a simple random sample

$$
DEFF=1+\rho(\bar{n}_j - 1)
$$

:::{.tc}
where $\rho$ is the ICC and $\bar{n}_j$ is the average cluster size
:::

- The square root of the design effect (DEFT) is what you need to multiply $SE_{\beta}$ by to *roughly* correct it for clustering bias^[We will learn some more accurate corrections next lecture.]

## Effective Sample Size

The design effect (DEFF) can also be used to calculate the [effective sample size]{.b .blue} $(n^*)$ accounting for clustering

$$
n^*=\frac{n}{1+\rho(\bar{n}_j - 1)}
$$

:::{.callout-note title="Implications"}
- Higher ICC $(\rho)$ reduces effective sample size (more bias)
- Higher cluster size reduces effective sample size (more bias)
- [Important:]{.b} $n^*$ applies primarily to **Level 1** effects. Power for **Level 2** effects depends mainly on the number of clusters ($J$), not the total $N$.
:::

## Brief Activity {background-color="#34495e" .fsmaller .white-text}

I recruited 30 participants to each complete 100 trials of a behavioral experiment; thus, my data has 3000 observations. I ran a linear regression and my hypothesized effect was significant! However, my annoying friend told me that I am ignoring "clustering" or something and that my effect might not be significant after all. My other, nice friend explained how to calculate the necessary information, but the software output only gave me Standard Deviations (SDs).

**Calculate the ICC, DEFF, DEFT, and $n^*$** given the following estimates:

- Between-participant SD (`tau00`): **1.20**
- Within-participant SD (`sigma`): **4.60**

## Answer Key

```{r}
tau00 <- 1.20
sigma <- 4.60
```

```{r}
(icc <- tau00^2 / (tau00^2 + sigma^2))
(deff <- 1 + icc * (100 - 1))
(deft <- sqrt(deff))
(neff <- (30 * 100) / deff)
```

## Interpretation

- The ICC is only 6.4\%, which may seem low
- However, the average cluster size is large (100)
- Because both matter, the SEs are about 2.7 times too small
- So, although my overall number of observations is 3000...
- My effective sample size at level 1 is only 411
- And my sample size at level 2 is only 30
- So, it is important to account for clustering here
