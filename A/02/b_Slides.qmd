---
format: 
  revealjs:
    css: ../../styles.css
    slide-number: true
    show-slide-number: all
    preview-links: false
    progress: true
    history: true
    hash-type: number
    theme: default
    code-block-background: true
    highlight-style: zenburn
    code-link: false
    code-copy: true
    code-line-numbers: false
    controls: true
    pagetitle: "Multilevel Modeling"
    author-meta: "Jeffrey Girard"
    semester: "Spring 2026"
    course: "PSYC 894"
    lecture: "02b"
execute:
  echo: true
  eval: true
  collapse: false
  cache: false
---

::: {.my-title}
# [Multilevel Modeling]{.blue}
Linear Modeling Review (2/2)

::: {.my-grey}
[{{< meta semester >}} | CLAS | {{< meta course >}}]{}<br />
[Jeffrey M. Girard | Lecture {{< meta lecture >}}]{}
:::

![](../../img/city-girl.svg){.absolute bottom=30 right=0 width="400"}
:::


## Roadmap

::: {.columns .pv4}
::: {.column width="60%"}
1. Continous-by-Continous<br />Variable Moderation
  
2. Continuous-by-Discrete<br />Variable Moderation

3. Assumptions, Diagnostics,<br />and Extensions of LM

:::

::: {.column .tc .pv4 width="40%"}
{{< lif "../../icons/map.json" trigger=hover colors=secondary:#2a76dd class=rc >}}
:::

:::

## Setup

```{r}
#| message: false

library(easystats)
library(ggplot2)
library(marginaleffects)
library(qqplotr)
library(sandwich)

# Set up default plot theme
theme_set(theme_bw(base_size = 30))
```

:::{.fsmaller}
**New Packages:**

- [qqplotr]{.b .green} is called by easystats to add CIs to diagnostic plots
- [sandwich]{.b .green} is called by easystats to implement HC3 corrections
:::

## Moderation {.smaller}

::: {.columns .pv4}
::: {.column width="60%"}
-   We may want to know if the effect of one predictor [depends on]{.b .green} the value on another predictor

::: {.fragment .mt1}
-   To answer these, we can test [interaction effects]{.b .blue}
    -   Interaction effects are just slopes for the [product]{.b .green} of two or more predictors
    -   Centering continous predictors is helpful

:::
::: {.fragment .mt1}
-   Types of bivariate moderation
    +   Continuous-by-Continuous Moderation (CCM)
    +   Continuous-by-Discrete Moderation (CDM)
    +   Discrete-by-Discrete Moderation (DDM)
    +   Higher-order (e.g., three-way) Moderation
:::
:::

::: {.column .tc .pv5 width="40%"}
{{< lif "../../icons/signpost.json" trigger=hover colors=secondary:#2a76dd class=rc >}}
:::
:::

# CCM

Continuous-by-Continuous Moderation

## CCM Equation

#### Generic
$$y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 (x_{1i} x_{2i}) + \varepsilon_{i}$$

#### Example
$$\text{MASS}_i = \beta_0 + \beta_1 \text{FLEN}_{i} + \beta_2 \text{BDEP}_{i} + \\
\beta_3 \text{FLEN}_i \text{BDEP}_i + \varepsilon_i$$

## CCM Formula

#### Generic
:::{.tc}
`y ~ 1 + x1 * x2`
:::

#### Example
:::{.tc}
`body_mass ~ 1 + flipper_len * bill_dep`
:::

## CCM Diagram {.nostretch}
![](../../diagrams/cc_moderation_full.png){width="50%"}

## CCM Estimation

```{r}
penguins_c <- center(penguins, select = c("flipper_len", "bill_dep"))
ccm_fb <- lm(
  formula = body_mass ~ 1 + flipper_len * bill_dep,
  data = penguins_c
)
```

:::{.pv4}
```{r}
model_parameters(ccm_fb)
```

:::

## CCM Interpretation {.smaller}

After centering the flipper length and bill depth predictors, ...

- **Intercept** $(\beta_0=4063.8$, $p<.001)$<br />
The expected body mass for a penguin with average flipper length and bill depth.

- **Flipper Length Simple Effect** $(\beta_1=48.6$, $p<.001)$<br />
The expected change in body mass associated with an increase of 1mm flipper length,<br />*specifically for a penguin with average bill depth*.

- **Bill Depth Simple Effect** $(\beta_2=44.6$, $p<.001)$<br />
The expected change in body mass associated with an increase of 1mm bill depth,<br />*specifically for a penguin with average flipper length*.

- **Flipper-Length-by-Bill-Depth Interaction Effect** $(\beta_3=-8.6$, $p<.001)$<br />
The expected change in the slope of one predictor for an increase of 1 in the other.<br />
*The negative sign here means the flipper length effect gets weaker as bills get deeper.*

## CCM Visualization 1

```{r}
#| fig-asp: 1
#| fig-width: 8
#| output-location: column

pred_ccmf <- estimate_relation(
  model = ccm_fb, 
  by = c(
    "flipper_len", 
    "bill_dep = [quartiles]"
  ), 
  estimate = "average"
)

plot(pred_ccmf) +
  labs(
    x = "Flipper Length", 
    y = "Body Mass", 
    color = "Bill Depth", 
    fill = "Bill Depth"
  ) +
  theme(legend.position = "top")
```

## CCM Visualization 2

```{r}
#| fig-asp: 1
#| fig-width: 9
#| output-location: column

pred_ccmb <- estimate_relation(
  model = ccm_fb, 
  by = c(
    "bill_dep", 
    "flipper_len = [quartiles]"
  ), 
  estimate = "average"
)

plot(pred_ccmb) +
  labs(
    x = "Bill Depth", 
    y = "Body Mass", 
    color = "Flipper Length", 
    fill = "Flipper Length"
  ) +
  theme(legend.position = "top")
```

## CCM Simple Slopes 1

```{r}
estimate_slopes(
  model = ccm_fb, 
  trend = "flipper_len", 
  by = "bill_dep = [quartiles]"
)
```

## CCM Simple Slopes 2

```{r}
estimate_slopes(
  model = ccm_fb, 
  trend = "bill_dep", 
  by = "flipper_len = [quartiles]"
)
```

# CDM

Continuous-by-Discrete Moderation

## CDM Equation {.smaller}

#### Generic
$$
\begin{aligned}
y_i &= \overbrace{(\beta_0 + \beta_2 D_{1i} + \dots)}^{\text{Group-Specific Intercept}}
+ \overbrace{(\beta_1 + \beta_3 D_{1i} + \dots)}^{\text{Group-Specific Slope}} \cdot x_i 
+ \varepsilon_i
\end{aligned}
$$

#### Example
$$
\begin{aligned}
\text{MASS}_i &= (\beta_0 + \beta_2 \text{CHIN}_{i} + \beta_3 \text{GENT}_i) \\
&\quad + (\beta_1 + \beta_4 \text{CHIN}_{i} + \beta_5 \text{GENT}_i) \cdot \text{FLEN}_i
+ \varepsilon_i
\end{aligned}
$$

## CDM Formula

#### Generic
:::{.tc}
`y ~ 1 + x * f`
:::

#### Example
:::{.tc}
`mass ~ 1 + flipper * species`
:::

## CDM Diagram {.nostretch}
![](../../diagrams/cb_moderation_full.png){width="50%"}

## CDM Estimation

```{r}
penguins_c <- center(penguins, select = "flipper_len")
cdm_fs <- lm(
  formula = body_mass ~ 1 + flipper_len * species, 
  data = penguins_c
)
```

:::{.pv4}
```{r}
#| echo: true

model_parameters(cdm_fs) |> print(select = "minimal")
```

:::

## CDM Interpretation 1 {.smaller}

After centering the Flipper Length predictor and setting Adelie as reference, ...

- **Intercept** $(\beta_0=4060.6$, $p<.001)$<br />
The expected body mass for an Adelie penguin with average flipper length.

- **Flipper Length Simple Effect** $(\beta_1=32.8$, $p<.001)$<br />
The expected change in mass associated with an increase of 1mm flipper length,<br />*specifically for the reference group (Adelie)*.

- **Chinstrap Simple Effect** $(\beta_2=-151.4$, $p=.062)$<br />
The difference in expected mass between Chinstrap and Adelie penguins,<br />*specifically for penguins with average flipper length*.

- **Gentoo Simple Effect** $(\beta_3=126.7$, $p=.242)$<br />
The difference in expected mass between Gentoo and Adelie penguins,<br />*specifically for penguins with average flipper length*.

## CDM Interpretation 2 {.smaller}
- **Flipper-by-Chinstrap Interaction Effect** $(\beta_4=1.7$, $p=.825)$<br />
The adjustment to the flipper slope for Chinstraps compared to Adelies.<br />
*The flipper--mass relationship is not significantly different for Chinstraps and Adelies.*

- **Flipper-by-Gentoo Interaction Effect** $(\beta_5=21.8$, $p=.002)$<br />
The adjustment to the flipper slope for Gentoos compared to Adelies.<br />
*The flipper--mass relationship is significantly steeper for Gentoos than for Adelies.*

## CDM Visualization

```{r}
#| fig-asp: 1
#| fig-width: 8.5
#| output-location: column

pred_cdmf <- estimate_relation(
  model = cdm_fs, 
  by = c(
    "flipper_len", 
    "species"
  ),
  estimate = "average"
)
plot(pred_cdmf) +
  labs(
    x = "Flipper Length",
    y = "Body Mass",
    color = "Species",
    fill = "Species"
  ) +
  theme(legend.position = "top")
```

## CDM Simple Slopes

```{r}
estimate_slopes(
  model = cdm_fs, 
  trend = "flipper_len", 
  by = "species"
)
```

:::{.fsmaller}
*Notice the Gentoo slope (54.6) is the Adelie slope (32.8) plus the interaction (21.8).*
:::

## A Formula Resource {.smaller}

<table width="100%">
<tr>
  <th>Formula</th>
  <th colspan=7>Slopes Estimated</th>
</tr>
<tr>
  <td width="30%">`y ~ x`</td>
  <td width="10%">$x$</td>
  <td width="10%"></td>
  <td width="10%"></td>
  <td width="10%"></td>
  <td width="10%"></td>
  <td width="10%"></td>
  <td width="10%"></td>
</tr>
<tr>
  <td>`y ~ x + w`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x * w`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td></td>
  <td>$xw$</td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x + w + z`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td>$z$</td>
  <td></td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x * w + z`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td>$z$</td>
  <td>$xw$</td>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x * (w + z)`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td>$z$</td>
  <td>$xw$</td>
  <td>$xz$</td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td>`y ~ (x + w + z)^2`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td>$z$</td>
  <td>$xw$</td>
  <td>$xz$</td>
  <td>$wz$</td>
  <td></td>
</tr>
<tr>
  <td>`y ~ x * w * z`</td>
  <td>$x$</td>
  <td>$w$</td>
  <td>$z$</td>
  <td>$xw$</td>
  <td>$xz$</td>
  <td>$wz$</td>
  <td>$xwz$</td>
</tr>
</table>

::: {.pv4 .f3}
Note that predictors can be continuous or discrete, but if a discrete predictor has more than two levels, you will end up with additional slopes due to dummy coding. To represent $g$ groups, it will create $g-1$ dummy codes (with a slope for each).
:::

# Linearity Assumption

## Overview {.smaller}

- **The Assumption:** The model matches the shape of the data
    + We assume the relationship is a straight line (additive)
    + *Intuition:* A one-unit increase in $x$ always produces the same increase in $y$

- **The Problem:** Mismatched shapes (misspecification)
    + Real relationships are often curved (practice effects, diminishing returns)
    + If we force a straight line onto a curve, our predictions will be wrong

- **The Solution:** Flexible modeling
    + *Simple Fix:* For basic curves, we add polynomial (e.g., quadratic) terms
    + *Advanced Fix:* For complex shapes, we use generalized additive modeling (GAM)
    + *Takeaway:* We transform the predictors to allow the model to bend

## Example

:::: {.columns}

::: {.column width="50%"}
```{r model-vis}
#| echo: true
#| fig.show: "hide"

# Does horsepower predict mpg?
fit_line <- lm(
  formula = mpg ~ 1 + hp, 
  data = mtcars
)
pred_line <- estimate_relation(
  model = fit_line, 
  by = "hp"
)
plot(pred_line, show_data = TRUE)
```

:::{.fsmaller}
**Note:** Adding horsepower hurts fuel economy, but this levels off (you can't go below 0 mpg), creating the curve that the linear model misses.
:::
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig-asp: 1
#| fig-width: 6.5
#| ref.label: "model-vis"
```
:::

::::

## Diagnostic

```{r}
#| fig-width: 8
#| fig-height: 4

# The reference line looks bad - major violation
check_model(fit_line, check = "linearity", base_size = 16)
```

## Simple Fix {.smaller}

- **The Trick:** Transform the Data, not the Parameters.
  + We can model curves by adding a squared term ($x^2$) as a new predictor.
  + [Still Linear]{.green}: $y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \varepsilon_i$
  + We can do this in R easily using `poly(x, degree = 2)` or `poly(x, 2)`
  + Since we are still just adding weighted terms, this remains a Linear Model (LM).

- **True Non-Linear Models (The "Illegal" Move):**
  + [Not Linear]{.red}: $y_i = \beta_0 \cdot x_i^{\beta_1}$
  + Here, the parameter is an exponent. This requires different math!

## Implementation

:::: {.columns}

::: {.column width="50%"}
```{r model-poly}
#| echo: true
#| fig.show: "hide"

fit_poly <- lm(
  formula = mpg ~ 1 + 
    poly(hp, 2, raw = TRUE), 
  data = mtcars
)

pred_poly <- estimate_relation(
  model = fit_poly, 
  by = "hp"
)
plot(pred_poly, show_data = TRUE)
```

:::{.fsmaller}
**Note:** By allowing the line to bend or curve (quadratically), we capture the relationship accurately.
:::
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig-asp: 1
#| fig-width: 6.5
#| ref.label: "model-poly"
```
:::

::::

# Homogeneity Assumption

## Overview {.smaller}

- **The Assumption:** The model is equally reliable everywhere
    + We assume the error is constant for all participants
    + *Intuition:* The model should predict low scores as precisely as high scores

- **The Problem:** Uneven reliability (heteroskedasticity)
  + The model is precise for some people but wildly guessing for others
  + *Visual:* A "megaphone" shape (errors spread out as values increase)
  + *Consequence:* Standard errors are wrong (usually too small)
  
- **The Solution:** Handling the noise
  + *Simple Fix:* Apply heteroskedasticity-consistent (HC3) standard errors
  + *Advanced Fix:* Model the error variance explicitly using location--scale models 
  + *Takeaway:* We stop assuming the noise is the same for everyone

## Example

:::: {.columns}

::: {.column width="50%"}
```{r model-hetero}
#| echo: true
#| fig.show: "hide"

# Does speed predict stop distance?
fit_cars <- lm(
  formula = dist ~ speed, 
  data = cars
)

pred_cars <- estimate_relation(
  fit_cars, 
  by = "speed"
)
plot(pred_cars, show_data = TRUE)
```

:::{.fsmaller}
**Note:** At low speeds, points are near the line. At high speeds, they spread out. We predict distance for "slow" stops well, but not for "fast" stops.
:::
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig-asp: 1
#| fig-width: 6.5
#| ref.label: "model-hetero"
```
:::

::::

## Diagnostic

```{r}
#| fig-width: 8
#| fig-height: 4

# The reference line looks fair - minor violation
check_model(fit_cars, check = "homogeneity", base_size = 16)
```

## Simple Fix {.smaller}

- **The Logic**:
    + We keep the parameter point estimates unchanged
    + We penalize the Standard Errors where variance is high
    + The creates "honest" $p$-values that account for noise
    + We use heteroskedasticity-consistent SEs (formula HC3)

- **The Intuition:**
    + **Standard (OLS):** Assumes the "noise level" is identical for everyone. It calculates one global variance ($\sigma^2$) and trusts it everywhere.
    + **Robust (HC3):** Acknowledges that **precision varies**. It uses the *actual* squared error of each observation ($\varepsilon_i^2$) to estimate the variance.
    + **The "Penalty":** If the model sees large errors in a specific area, it "learns" that the slope is unstable there and inflates the SE to reflect that uncertainty.

## Implementation

```{r}
model_parameters(fit_cars)  # standard OLS results
```

```{r}
model_parameters(fit_cars, vcov = "HC3") # fix
```

:::{.fsmaller}
**Observation:** In this case, the penalty is small! But we pay it anyway because it ensures our inferences and conclusions are valid.
:::

# Normality Assumption

## Overview {.smaller}

- **The Assumption:** The errors follow a bell curve
  + We assume the residuals are normally distributed around zero
  + *Intuition:* Most prediction errors are small; extreme errors are rare and symmetric

- **The Problem:** Non-normality of error
  + The residuals might be skewed, bounded, or have "heavy tails"
  + *Consequence:* p-values are untrustworthy, especially in small samples ($n<50$)

- **The Solution:** Changing the Assumptions
  + *Simple Fix:* We resample or "bootstrap" our own data to build empirical estimates of uncertainty without assuming any shape for the sampling distribution
  + *Advanced Fix:* We explicitly model the error distribution using Generalized Linear Modeling (GLM), e.g., logistic for binary, poisson for counts, cumulative for ordinal
  + *Takeaway:* We stop forcing non-normal data into a normal shape.

## Example

:::: {.columns}

::: {.column width="50%"}
```{r model-norm}
#| echo: true
#| fig.show: "hide"

# Does wind speed predict ozone?
fit_ozone <- lm(
  formula = Ozone ~ Wind, 
  data = airquality
)

pred_ozone <- estimate_relation(
  model = fit_ozone, 
  by = "Wind"
)
plot(pred_ozone, show_data = TRUE)
```

:::{.fsmaller}
**Note:** The model fits a straight line, but there are outliers and negative Ozone (impossible) is being predicted.
:::
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| fig-asp: 1
#| fig-width: 6.5
#| ref.label: "model-norm"
```
:::

::::

## Diagnostic

```{r}
#| fig-width: 12
#| fig-height: 6

# Distributions look fair - minor violation
check_model(fit_ozone, check = c("normality", "qq"), base_size = 18)
```


## Simple Fix {.smaller}

- **The Logic:**
    + If the residuals aren't Normal, the formulas for SEs and CIs are wrong
    + Resampling methods like **bootstrapping** skips the formulas
    + We simulate repeating the experiment 2,000 times using our own data
    + This is done by sampling $n$ observations each time *with replacement*
    + If 95% of those simulations show a negative slope, the effect is reliable

- **The Intuition:**
    + **Standard (Parametric):** "I assume the sampling distribution is a perfect bell curve."
    + **Bootstrap (Non-Parametric):** "I don't assume anything about the shape of the sampling distribution. I built the distribution myself by reshuffling the data."

## Implementation

```{r}
model_parameters(fit_ozone) # standard OLS results
```

```{r}
model_parameters(fit_ozone, bootstrap = TRUE, iterations = 2000) # fix
```

:::{.fsmaller}
**Observation:** The confidence interval changed slightly. Because we had a decent sample size ($n=153$), the Central Limit Theorem helped the standard approach. In smaller samples, the difference would likely be larger.
:::


# Independence Assumption

## Preview {.smaller}

- **The Assumption:** The residuals are independent
    + We assume that every data point provides unique, unrelated information
    + *Intuition:* Knowing the error for observation $i$ tells us nothing about observation $j$

- **The Problem:** Clustering and dependency
    + Observations are often related (e.g., repeated measures, students nested in schools)
    + *Consequence:* The "effective" sample size is much smaller than $n$, leading to an overestimation of confidence (e.g., $p$-values are too small, Type I errors)

- **The Solution:** Addressing the structure
    + *Simple Fix:* Cluster-robust SEs or Fixed effects (dummy codes) per cluster
    + *Advanced Fix:* Generalized estimating equations (GEE) or Multilevel models (MLM)
    + *Takeaway:* We stop assuming rows are independent and model the hierarchy
    
