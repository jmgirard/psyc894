{
  "hash": "be2dfd64bf88fb8f7b897f5487b86fec",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat: \n  revealjs:\n    css: ../../styles.css\n    slide-number: true\n    show-slide-number: all\n    preview-links: false\n    progress: true\n    history: true\n    hash-type: number\n    theme: default\n    code-block-background: true\n    highlight-style: zenburn\n    code-link: false\n    code-copy: true\n    code-line-numbers: false\n    controls: true\n    pagetitle: \"Multilevel Modeling\"\n    author-meta: \"Jeffrey Girard\"\n    semester: \"Spring 2026\"\n    course: \"PSYC 894\"\n    lecture: \"02b\"\nexecute:\n  echo: true\n  eval: true\n  collapse: false\n  cache: false\n---\n\n::: {.my-title}\n# [Multilevel Modeling]{.blue}\nLinear Modeling Review (2/2)\n\n::: {.my-grey}\n[{{< meta semester >}} | CLAS | {{< meta course >}}]{}<br />\n[Jeffrey M. Girard | Lecture {{< meta lecture >}}]{}\n:::\n\n![](../../img/city-girl.svg){.absolute bottom=30 right=0 width=\"400\"}\n:::\n\n\n## Roadmap\n\n::: {.columns .pv4}\n::: {.column width=\"60%\"}\n1. Continous-by-Continous<br />Variable Moderation\n  \n2. Continuous-by-Discrete<br />Variable Moderation\n\n3. Assumptions, Diagnostics,<br />and Extensions of LM\n\n:::\n\n::: {.column .tc .pv4 width=\"40%\"}\n{{< lif \"../../icons/map.json\" trigger=hover colors=secondary:#2a76dd class=rc >}}\n:::\n\n:::\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(easystats)\nlibrary(ggplot2)\nlibrary(marginaleffects)\nlibrary(qqplotr)\nlibrary(sandwich)\n\ndata(\"penguins\", \"mtcars\", \"cars\", \"airquality\")\n\ntheme_set(theme_bw(base_size = 30))\n```\n:::\n\n\n:::{.fsmaller}\n**New Packages:**\n\n- [qqplotr]{.b .green} is called by easystats to add CIs to diagnostic plots\n- [sandwich]{.b .green} is called by easystats to implement HC3 corrections\n:::\n\n## Moderation {.smaller}\n\n::: {.columns .pv4}\n::: {.column width=\"60%\"}\n-   We may want to know if the effect of one predictor [depends on]{.b .green} the value on another predictor\n\n::: {.fragment .mt1}\n-   To answer these, we can test [interaction effects]{.b .blue}\n    -   Interaction effects are just slopes for the [product]{.b .green} of two or more predictors\n    -   Centering continous predictors is helpful\n\n:::\n::: {.fragment .mt1}\n-   Types of bivariate moderation\n    +   Continuous-by-Continuous Moderation (CCM)\n    +   Continuous-by-Discrete Moderation (CDM)\n    +   Discrete-by-Discrete Moderation (DDM)\n    +   Higher-order (e.g., three-way) Moderation\n:::\n:::\n\n::: {.column .tc .pv5 width=\"40%\"}\n{{< lif \"../../icons/signpost.json\" trigger=hover colors=secondary:#2a76dd class=rc >}}\n:::\n:::\n\n# CCM\n\nContinuous-by-Continuous Moderation\n\n## CCM Equation\n\n#### Generic\n$$y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 (x_{1i} x_{2i}) + \\varepsilon_{i}$$\n\n#### Example\n$$\\text{MASS}_i = \\beta_0 + \\beta_1 \\text{FLEN}_{i} + \\beta_2 \\text{BDEP}_{i} + \\\\\n\\beta_3 \\text{FLEN}_i \\text{BDEP}_i + \\varepsilon_i$$\n\n## CCM Formula\n\n#### Generic\n:::{.tc}\n`y ~ 1 + x1 * x2`\n:::\n\n#### Example\n:::{.tc}\n`body_mass ~ 1 + flipper_len * bill_dep`\n:::\n\n## CCM Diagram {.nostretch}\n![](../../diagrams/cc_moderation_full.png){width=\"50%\"}\n\n## CCM Estimation\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_c <- center(penguins, select = c(\"flipper_len\", \"bill_dep\"))\nccm_fb <- lm(\n  formula = body_mass ~ 1 + flipper_len * bill_dep,\n  data = penguins_c\n)\n```\n:::\n\n\n:::{.pv4}\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(ccm_fb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter              | Coefficient |    SE |             95% CI | t(338) |      p\n-----------------------------------------------------------------------------------\n(Intercept)            |     4062.79 | 29.56 | [4004.65, 4120.93] | 137.46 | < .001\nflipper len            |       48.63 |  1.82 | [  45.05,   52.22] |  26.71 | < .001\nbill dep               |       44.64 | 13.02 | [  19.04,   70.25] |   3.43 | < .001\nflipper len × bill dep |       -8.60 |  1.34 | [ -11.23,   -5.96] |  -6.41 | < .001\n```\n\n\n:::\n:::\n\n\n:::\n\n## CCM Interpretation {.smaller}\n\nAfter centering the flipper length and bill depth predictors, ...\n\n- **Intercept** $(\\beta_0=4063.8$, $p<.001)$<br />\nThe expected body mass for a penguin with average flipper length and bill depth.\n\n- **Flipper Length Simple Effect** $(\\beta_1=48.6$, $p<.001)$<br />\nThe expected change in body mass associated with an increase of 1mm flipper length,<br />*specifically for a penguin with average bill depth*.\n\n- **Bill Depth Simple Effect** $(\\beta_2=44.6$, $p<.001)$<br />\nThe expected change in body mass associated with an increase of 1mm bill depth,<br />*specifically for a penguin with average flipper length*.\n\n- **Flipper-Length-by-Bill-Depth Interaction Effect** $(\\beta_3=-8.6$, $p<.001)$<br />\nThe expected change in the slope of one predictor for an increase of 1 in the other.<br />\n*The negative sign here means the flipper length effect gets weaker as bills get deeper.*\n\n## CCM Visualization 1\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\npred_ccmf <- estimate_relation(\n  model = ccm_fb, \n  by = c(\n    \"flipper_len\", \n    \"bill_dep = [quartiles]\"\n  ), \n  estimate = \"average\"\n)\n\nplot(pred_ccmf) +\n  labs(\n    x = \"Flipper Length\", \n    y = \"Body Mass\", \n    color = \"Bill Depth\", \n    fill = \"Bill Depth\"\n  ) +\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-4-1.png){width=768}\n:::\n:::\n\n\n## CCM Visualization 2\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\npred_ccmb <- estimate_relation(\n  model = ccm_fb, \n  by = c(\n    \"bill_dep\", \n    \"flipper_len = [quartiles]\"\n  ), \n  estimate = \"average\"\n)\n\nplot(pred_ccmb) +\n  labs(\n    x = \"Bill Depth\", \n    y = \"Body Mass\", \n    color = \"Flipper Length\", \n    fill = \"Flipper Length\"\n  ) +\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-5-1.png){width=864}\n:::\n:::\n\n\n## CCM Simple Slopes 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate_slopes(\n  model = ccm_fb, \n  trend = \"flipper_len\", \n  by = \"bill_dep = [quartiles]\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Marginal Effects\n\nbill_dep | Slope |   SE |         95% CI | t(338) |      p\n----------------------------------------------------------\n-1.55    | 61.97 | 2.40 | [57.25, 66.69] |  25.84 | < .001\n0.15     | 47.35 | 1.88 | [43.65, 51.05] |  25.18 | < .001\n1.55     | 35.32 | 3.08 | [29.25, 41.38] |  11.45 | < .001\n\nMarginal effects estimated for flipper_len\nType of slope was dY/dX\n```\n\n\n:::\n:::\n\n\n## CCM Simple Slopes 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate_slopes(\n  model = ccm_fb, \n  trend = \"bill_dep\", \n  by = \"flipper_len = [quartiles]\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Marginal Effects\n\nflipper_len |  Slope |    SE |           95% CI | t(338) |      p\n-----------------------------------------------------------------\n-10.91      | 138.47 | 22.01 | [ 95.17, 181.77] |   6.29 | < .001\n-3.92       |  78.30 | 15.28 | [ 48.25, 108.34] |   5.13 | < .001\n12.09       | -59.25 | 17.90 | [-94.46, -24.03] |  -3.31 |  0.001\n\nMarginal effects estimated for bill_dep\nType of slope was dY/dX\n```\n\n\n:::\n:::\n\n\n# CDM\n\nContinuous-by-Discrete Moderation\n\n## CDM Equation {.smaller}\n\n#### Generic\n$$\n\\begin{aligned}\ny_i &= \\overbrace{(\\beta_0 + \\beta_2 D_{1i} + \\dots)}^{\\text{Group-Specific Intercept}}\n+ \\overbrace{(\\beta_1 + \\beta_3 D_{1i} + \\dots)}^{\\text{Group-Specific Slope}} \\cdot x_i \n+ \\varepsilon_i\n\\end{aligned}\n$$\n\n#### Example\n$$\n\\begin{aligned}\n\\text{MASS}_i &= (\\beta_0 + \\beta_2 \\text{CHIN}_{i} + \\beta_3 \\text{GENT}_i) \\\\\n&\\quad + (\\beta_1 + \\beta_4 \\text{CHIN}_{i} + \\beta_5 \\text{GENT}_i) \\cdot \\text{FLEN}_i\n+ \\varepsilon_i\n\\end{aligned}\n$$\n\n## CDM Formula\n\n#### Generic\n:::{.tc}\n`y ~ 1 + x * f`\n:::\n\n#### Example\n:::{.tc}\n`mass ~ 1 + flipper * species`\n:::\n\n## CDM Diagram {.nostretch}\n![](../../diagrams/cb_moderation_full.png){width=\"50%\"}\n\n## CDM Estimation\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_c <- center(penguins, select = \"flipper_len\")\ncdm_fs <- lm(\n  formula = body_mass ~ 1 + flipper_len * species, \n  data = penguins_c\n)\n```\n:::\n\n\n:::{.pv4}\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(cdm_fs) |> print(select = \"minimal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter                         | Coefficient |             95% CI |      p\n-----------------------------------------------------------------------------\n(Intercept)                       |     4060.55 | [3944.47, 4176.62] | < .001\nflipper len                       |       32.83 | [  23.73,   41.93] | < .001\nspecies [Chinstrap]               |     -151.42 | [-310.58,    7.73] | 0.062 \nspecies [Gentoo]                  |      126.66 | [ -85.98,  339.31] | 0.242 \nflipper len × species [Chinstrap] |        1.74 | [ -13.71,   17.19] | 0.825 \nflipper len × species [Gentoo]    |       21.79 | [   8.14,   35.44] | 0.002 \n```\n\n\n:::\n:::\n\n\n:::\n\n## CDM Interpretation 1 {.smaller}\n\nAfter centering the Flipper Length predictor and setting Adelie as reference, ...\n\n- **Intercept** $(\\beta_0=4060.6$, $p<.001)$<br />\nThe expected body mass for an Adelie penguin with average flipper length.\n\n- **Flipper Length Simple Effect** $(\\beta_1=32.8$, $p<.001)$<br />\nThe expected change in mass associated with an increase of 1mm flipper length,<br />*specifically for the reference group (Adelie)*.\n\n- **Chinstrap Simple Effect** $(\\beta_2=-151.4$, $p=.062)$<br />\nThe difference in expected mass between Chinstrap and Adelie penguins,<br />*specifically for penguins with average flipper length*.\n\n- **Gentoo Simple Effect** $(\\beta_3=126.7$, $p=.242)$<br />\nThe difference in expected mass between Gentoo and Adelie penguins,<br />*specifically for penguins with average flipper length*.\n\n## CDM Interpretation 2 {.smaller}\n- **Flipper-by-Chinstrap Interaction Effect** $(\\beta_4=1.7$, $p=.825)$<br />\nThe adjustment to the flipper slope for Chinstraps compared to Adelies.<br />\n*The flipper--mass relationship is not significantly different for Chinstraps and Adelies.*\n\n- **Flipper-by-Gentoo Interaction Effect** $(\\beta_5=21.8$, $p=.002)$<br />\nThe adjustment to the flipper slope for Gentoos compared to Adelies.<br />\n*The flipper--mass relationship is significantly steeper for Gentoos than for Adelies.*\n\n## CDM Visualization\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\npred_cdmf <- estimate_relation(\n  model = cdm_fs, \n  by = c(\n    \"flipper_len\", \n    \"species\"\n  ),\n  estimate = \"average\"\n)\nplot(pred_cdmf) +\n  labs(\n    x = \"Flipper Length\",\n    y = \"Body Mass\",\n    color = \"Species\",\n    fill = \"Species\"\n  ) +\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-10-1.png){width=816}\n:::\n:::\n\n\n## CDM Simple Slopes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate_slopes(\n  model = cdm_fs, \n  trend = \"flipper_len\", \n  by = \"species\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Marginal Effects\n\nspecies   | Slope |   SE |         95% CI | t(336) |      p\n-----------------------------------------------------------\nAdelie    | 32.83 | 4.63 | [23.73, 41.93] |   7.10 | < .001\nChinstrap | 34.57 | 6.33 | [22.11, 47.03] |   5.46 | < .001\nGentoo    | 54.62 | 5.17 | [44.46, 64.79] |  10.57 | < .001\n\nMarginal effects estimated for flipper_len\nType of slope was dY/dX\n```\n\n\n:::\n:::\n\n\n:::{.fsmaller}\n*Notice the Gentoo slope (54.6) is the Adelie slope (32.8) plus the interaction (21.8).*\n:::\n\n## A Formula Resource {.smaller}\n\n<table width=\"100%\">\n<tr>\n  <th>Formula</th>\n  <th colspan=7>Slopes Estimated</th>\n</tr>\n<tr>\n  <td width=\"30%\">`y ~ x`</td>\n  <td width=\"10%\">$x$</td>\n  <td width=\"10%\"></td>\n  <td width=\"10%\"></td>\n  <td width=\"10%\"></td>\n  <td width=\"10%\"></td>\n  <td width=\"10%\"></td>\n  <td width=\"10%\"></td>\n</tr>\n<tr>\n  <td>`y ~ x + w`</td>\n  <td>$x$</td>\n  <td>$w$</td>\n  <td></td>\n  <td></td>\n  <td></td>\n  <td></td>\n  <td></td>\n</tr>\n<tr>\n  <td>`y ~ x * w`</td>\n  <td>$x$</td>\n  <td>$w$</td>\n  <td></td>\n  <td>$xw$</td>\n  <td></td>\n  <td></td>\n  <td></td>\n</tr>\n<tr>\n  <td>`y ~ x + w + z`</td>\n  <td>$x$</td>\n  <td>$w$</td>\n  <td>$z$</td>\n  <td></td>\n  <td></td>\n  <td></td>\n  <td></td>\n</tr>\n<tr>\n  <td>`y ~ x * w + z`</td>\n  <td>$x$</td>\n  <td>$w$</td>\n  <td>$z$</td>\n  <td>$xw$</td>\n  <td></td>\n  <td></td>\n  <td></td>\n</tr>\n<tr>\n  <td>`y ~ x * (w + z)`</td>\n  <td>$x$</td>\n  <td>$w$</td>\n  <td>$z$</td>\n  <td>$xw$</td>\n  <td>$xz$</td>\n  <td></td>\n  <td></td>\n</tr>\n<tr>\n  <td>`y ~ (x + w + z)^2`</td>\n  <td>$x$</td>\n  <td>$w$</td>\n  <td>$z$</td>\n  <td>$xw$</td>\n  <td>$xz$</td>\n  <td>$wz$</td>\n  <td></td>\n</tr>\n<tr>\n  <td>`y ~ x * w * z`</td>\n  <td>$x$</td>\n  <td>$w$</td>\n  <td>$z$</td>\n  <td>$xw$</td>\n  <td>$xz$</td>\n  <td>$wz$</td>\n  <td>$xwz$</td>\n</tr>\n</table>\n\n::: {.pv4 .f3}\nNote that predictors can be continuous or discrete, but if a discrete predictor has more than two levels, you will end up with additional slopes due to dummy coding. To represent $g$ groups, it will create $g-1$ dummy codes (with a slope for each).\n:::\n\n# Linearity Assumption\n\n## Overview {.smaller}\n\n- **The Assumption:** The model matches the shape of the data\n    + We assume the relationship is a straight line (additive)\n    + *Intuition:* A one-unit increase in $x$ always produces the same increase in $y$\n\n- **The Problem:** Mismatched shapes (misspecification)\n    + Real relationships are often curved (practice effects, diminishing returns)\n    + If we force a straight line onto a curve, our predictions will be wrong\n\n- **The Solution:** Flexible modeling\n    + *Simple Fix:* For basic curves, we add polynomial (e.g., quadratic) terms\n    + *Advanced Fix:* For complex shapes, we use generalized additive modeling (GAM)\n    + *Takeaway:* We transform the predictors to allow the model to bend\n\n## Example\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Does horsepower predict mpg?\nfit_line <- lm(\n  formula = mpg ~ 1 + hp, \n  data = mtcars\n)\npred_line <- estimate_relation(\n  model = fit_line, \n  by = \"hp\"\n)\nplot(pred_line, show_data = TRUE)\n```\n:::\n\n\n:::{.fsmaller}\n**Note:** Adding horsepower hurts fuel economy, but this levels off (you can't go below 0 mpg), creating the curve that the linear model misses.\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-12-1.png){width=624}\n:::\n:::\n\n:::\n\n::::\n\n## Diagnostic\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# The reference line looks bad - major violation\ncheck_model(fit_line, check = \"linearity\", base_size = 16)\n```\n\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-13-1.png){width=768}\n:::\n:::\n\n\n## Simple Fix {.smaller}\n\n- **The Trick:** Transform the Data, not the Parameters.\n  + We can model curves by adding a squared term ($x^2$) as a new predictor.\n  + [Still Linear]{.green}: $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\varepsilon_i$\n  + We can do this in R easily using `poly(x, degree = 2)` or `poly(x, 2)`\n  + Since we are still just adding weighted terms, this remains a Linear Model (LM).\n\n- **True Non-Linear Models (The \"Illegal\" Move):**\n  + [Not Linear]{.red}: $y_i = \\beta_0 \\cdot x_i^{\\beta_1}$\n  + Here, the parameter is an exponent. This requires different math!\n\n## Implementation\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_poly <- lm(\n  formula = mpg ~ 1 + \n    poly(hp, 2, raw = TRUE), \n  data = mtcars\n)\n\npred_poly <- estimate_relation(\n  model = fit_poly, \n  by = \"hp\"\n)\nplot(pred_poly, show_data = TRUE)\n```\n:::\n\n\n:::{.fsmaller}\n**Note:** By allowing the line to bend or curve (quadratically), we capture the relationship accurately.\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-14-1.png){width=624}\n:::\n:::\n\n:::\n\n::::\n\n# Homogeneity Assumption\n\n## Overview {.smaller}\n\n- **The Assumption:** The model is equally reliable everywhere\n    + We assume the error is constant for all participants\n    + *Intuition:* The model should predict low scores as precisely as high scores\n\n- **The Problem:** Uneven reliability (heteroskedasticity)\n  + The model is precise for some people but wildly guessing for others\n  + *Visual:* A \"megaphone\" shape (errors spread out as values increase)\n  + *Consequence:* Standard errors are wrong (usually too small)\n  \n- **The Solution:** Handling the noise\n  + *Simple Fix:* Apply heteroskedasticity-consistent (HC3) standard errors\n  + *Advanced Fix:* Model the error variance explicitly using location--scale models \n  + *Takeaway:* We stop assuming the noise is the same for everyone\n\n## Example\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Does speed predict stop distance?\nfit_cars <- lm(\n  formula = dist ~ speed, \n  data = cars\n)\n\npred_cars <- estimate_relation(\n  fit_cars, \n  by = \"speed\"\n)\nplot(pred_cars, show_data = TRUE)\n```\n:::\n\n\n:::{.fsmaller}\n**Note:** At low speeds, points are near the line. At high speeds, they spread out. We predict distance for \"slow\" stops well, but not for \"fast\" stops.\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-15-1.png){width=624}\n:::\n:::\n\n:::\n\n::::\n\n## Diagnostic\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# The reference line looks fair - minor violation\ncheck_model(fit_cars, check = \"homogeneity\", base_size = 16)\n```\n\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-16-1.png){width=768}\n:::\n:::\n\n\n## Simple Fix {.smaller}\n\n- **The Logic**:\n    + We keep the parameter point estimates unchanged\n    + We penalize the Standard Errors where variance is high\n    + The creates \"honest\" $p$-values that account for noise\n    + We use heteroskedasticity-consistent SEs (formula HC3)\n\n- **The Intuition:**\n    + **Standard (OLS):** Assumes the \"noise level\" is identical for everyone. It calculates one global variance ($\\sigma^2$) and trusts it everywhere.\n    + **Robust (HC3):** Acknowledges that **precision varies**. It uses the *actual* squared error of each observation ($\\varepsilon_i^2$) to estimate the variance.\n    + **The \"Penalty\":** If the model sees large errors in a specific area, it \"learns\" that the slope is unstable there and inflates the SE to reflect that uncertainty.\n\n## Implementation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(fit_cars)  # standard OLS results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter   | Coefficient |   SE |          95% CI | t(48) |      p\n-------------------------------------------------------------------\n(Intercept) |      -17.58 | 6.76 | [-31.17, -3.99] | -2.60 | 0.012 \nspeed       |        3.93 | 0.42 | [  3.10,  4.77] |  9.46 | < .001\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(fit_cars, vcov = \"HC3\") # fix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter   | Coefficient |   SE |          95% CI | t(48) |      p\n-------------------------------------------------------------------\n(Intercept) |      -17.58 | 5.93 | [-29.51, -5.65] | -2.96 | 0.005 \nspeed       |        3.93 | 0.43 | [  3.07,  4.79] |  9.20 | < .001\n```\n\n\n:::\n:::\n\n\n:::{.fsmaller}\n**Observation:** In this case, the penalty is small! But we pay it anyway because it ensures our inferences and conclusions are valid.\n:::\n\n# Normality Assumption\n\n## Overview {.smaller}\n\n- **The Assumption:** The errors follow a bell curve\n  + We assume the residuals are normally distributed around zero\n  + *Intuition:* Most prediction errors are small; extreme errors are rare and symmetric\n\n- **The Problem:** Non-normality of error\n  + The residuals might be skewed, bounded, or have \"heavy tails\"\n  + *Consequence:* p-values are untrustworthy, especially in small samples ($n<50$)\n\n- **The Solution:** Changing the Assumptions\n  + *Simple Fix:* We resample or \"bootstrap\" our own data to build empirical estimates of uncertainty without assuming any shape for the sampling distribution\n  + *Advanced Fix:* We explicitly model the error distribution using Generalized Linear Modeling (GLM), e.g., logistic for binary, poisson for counts, cumulative for ordinal\n  + *Takeaway:* We stop forcing non-normal data into a normal shape.\n\n## Example\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Does wind speed predict ozone?\nfit_ozone <- lm(\n  formula = Ozone ~ Wind, \n  data = airquality\n)\n\npred_ozone <- estimate_relation(\n  model = fit_ozone, \n  by = \"Wind\"\n)\nplot(pred_ozone, show_data = TRUE)\n```\n:::\n\n\n:::{.fsmaller}\n**Note:** The model fits a straight line, but there are outliers and negative Ozone (impossible) is being predicted.\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-19-1.png){width=624}\n:::\n:::\n\n:::\n\n::::\n\n## Diagnostic\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Distributions look fair - minor violation\ncheck_model(fit_ozone, check = c(\"qq\", \"normality\"), base_size = 18)\n```\n\n::: {.cell-output-display}\n![](b_Slides_files/figure-revealjs/unnamed-chunk-20-1.png){width=1152}\n:::\n:::\n\n\n\n## Simple Fix {.smaller}\n\n- **The Logic:**\n    + If the residuals aren't Normal, the formulas for SEs and CIs are wrong\n    + Resampling methods like **bootstrapping** skips the formulas\n    + We simulate repeating the experiment 2,000 times using our own data\n    + This is done by sampling $n$ observations each time *with replacement*\n    + If 95% of those simulations show a negative slope, the effect is reliable\n\n- **The Intuition:**\n    + **Standard (Parametric):** \"I assume the sampling distribution is a perfect bell curve.\"\n    + **Bootstrap (Non-Parametric):** \"I don't assume anything about the shape of the sampling distribution. I built the distribution myself by reshuffling the data.\"\n\n## Implementation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(fit_ozone) # standard OLS results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter   | Coefficient |   SE |          95% CI | t(114) |      p\n--------------------------------------------------------------------\n(Intercept) |       96.87 | 7.24 | [82.53, 111.21] |  13.38 | < .001\nWind        |       -5.55 | 0.69 | [-6.92,  -4.18] |  -8.04 | < .001\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(fit_ozone, bootstrap = TRUE, iterations = 2000) # fix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter   | Coefficient |          95% CI |      p\n----------------------------------------------------\n(Intercept) |       97.00 | [79.13, 115.05] | < .001\nWind        |       -5.56 | [-7.24,  -4.03] | < .001\n```\n\n\n:::\n:::\n\n\n:::{.fsmaller}\n**Observation:** The confidence interval changed slightly. Because we had a decent sample size ($n=153$), the Central Limit Theorem helped the standard approach. In smaller samples, the difference would likely be larger.\n:::\n\n\n# Independence Assumption\n\n## Preview {.smaller}\n\n- **The Assumption:** The residuals are independent\n    + We assume that every data point provides unique, unrelated information\n    + *Intuition:* Knowing the error for observation $i$ tells us nothing about observation $j$\n\n- **The Problem:** Clustering and dependency\n    + Observations are often related (e.g., repeated measures, students nested in schools)\n    + *Consequence:* The \"effective\" sample size is much smaller than $n$, leading to an overestimation of confidence (e.g., $p$-values are too small, Type I errors)\n\n- **The Solution:** Addressing the structure\n    + *Simple Fix:* Cluster-robust SEs or Fixed effects (dummy codes) per cluster\n    + *Advanced Fix:* Generalized estimating equations (GEE) or Multilevel models (MLM)\n    + *Takeaway:* We stop assuming rows are independent and model the hierarchy\n    \n",
    "supporting": [
      "b_Slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}