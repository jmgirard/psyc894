{
  "hash": "459b8f491e6fcd3ece9912d5c811e25a",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat: \n  revealjs:\n    css: ../../styles.css\n    slide-number: true\n    show-slide-number: all\n    preview-links: false\n    progress: true\n    history: true\n    hash-type: number\n    theme: default\n    code-block-background: true\n    highlight-style: zenburn\n    code-link: false\n    code-copy: true\n    code-line-numbers: false\n    controls: true\n    pagetitle: \"Multilevel Modeling\"\n    author-meta: \"Jeffrey Girard\"\n    semester: \"Spring 2026\"\n    course: \"PSYC 894\"\n    lecture: \"04a\"\nexecute:\n  echo: false\n  eval: true\n  collapse: false\n  cache: false\n---\n\n::: {.my-title}\n# [Multilevel Modeling]{.blue}\nEstimation Strategies\n\n::: {.my-grey}\n[{{< meta semester >}} | CLAS | {{< meta course >}}]{}<br />\n[Jeffrey M. Girard | Lecture {{< meta lecture >}}]{}\n:::\n\n![](../../img/city-girl.svg){.absolute bottom=30 right=0 width=\"400\"}\n:::\n\n\n::: {.cell}\n\n:::\n\n\n## Roadmap\n\n::: {.columns .pv4}\n\n::: {.column width=\"60%\"}\n1. Ordinary Least Squares\n    + *Goals, Estimates, Intuition*\n\n2. Maximum Likelihood\n    + *Goals, Versions, Optimizers*\n\n3. Bayesian Overview\n    + *Basics, Priors, MCMC*\n    \n:::\n\n::: {.column .tc .pv4 width=\"40%\"}\n{{< lif \"../../icons/map.json\" trigger=hover colors=secondary:#2a76dd class=rc >}}\n:::\n\n:::\n\n# Ordinary Least Squares\n\n## Goals and Objectives\n\n- We want to estimate population parameters from a sample\n    1. Select a \"loss function\" that measures estimation quality\n    2. Find the parameter values that optimize this function\n\n:::{.fragment}\n- `lm()` uses Ordinary Least Squares (OLS) estimation\n    + The loss function is the sum of squared residuals (SSR)\n    + We can simply optimize this function using calculus\n\n:::\n\n## OLS Estimates\n\n- Imagine calculating SSR for every possible $\\beta$ estimate\n\n- Plot the estimated values on $x$ and their SSR values on $y$\n\n:::{.fragment}\n- SSR will be smallest at the true population parameter value\n\n- SSR will increase as estimates move away from this value\n\n- The plotted loss function will appear quadratic (like a U)\n\n:::\n\n:::{.fragment}\n- The OLS estimates will be at the bottom of that curve\n\n- This is when the derivative of the loss function equals zero\n\n:::\n\n## Loss Function \n\nHere is our imagined plot when the true value is $\\beta=3.0$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n## Derivative at Zero\n\nThe derivative is the slope of the tangent line\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n## The OLS Solution {.fsmaller}\n\n- Because OLS makes simple assumptions, we don't need to guess.\n- Calculus gives us a direct \"closed-form\" solution.\n\n:::{.fragment}\n**In Simple Regression:**\n$$Slope = \\frac{\\text{Covariance}(X,Y)}{\\text{Variance}(X)}$$\n:::\n\n:::{.fragment}\n- This is essentially a \"Variance-Weighted Correlation.\"\n- It tells us how much $Y$ changes as $X$ changes, relative to the spread of $X$.\n:::\n\n## Generalizing OLS\n\n- **Multiple Regression**\n    + The logic is exactly the same, but we use Matrix Algebra.\n    + It accounts for the covariance between *all* predictors simultaneously.\n    \n:::{.fragment}\n- **The Takeaway**\n    + OLS is fast and precise because we can solve it directly.\n    + We jump straight to the bottom of the \"U\" curve.\n    + ... But only if the assumptions are met.\n:::\n\n# Maximum Likelihood\n\n## Recap: Why not OLS?\n\n- **Recall from last lecture:**\n    + OLS assumes errors are [independent]{.b .blue}.\n    + Clustered data (students in schools) violates this.\n    \n:::{.fragment}\n- **The Consequence:**\n    + OLS thinks we have more unique information than we do.\n    + Standard Errors are underestimated.\n    + [Result:]{.b .red} Drastically inflated Type I Error (False Positives).\n:::\n\n## Goals {.fsmaller}\n\n- Because of this, ***OLS cannot be used*** for multilevel models\n\n:::{.fragment}\n- [Maximum Likelihood Estimation]{.b .blue} (MLE) is often used\n    + **The Concept:** We want to *maximize* the [Likelihood]{.b .green}, which asks: *\"If the population parameter were $X$, how probable would our data be?\"*\n    + **The Goal:** Find the parameter values that make our observed data **most probable** (i.e., the top of the Likelihood hill).\n\n:::\n:::{.fragment}\n- **Computational Note:**\n    + To make the math easier, software actually *minimizes* a transformation of the Likelihood: the [Negative Log-Likelihood ($-LL$)]{.b .green}\n    + *Intuition:* We flip the \"Likelihood Hill\" upside down into a \"Loss Valley\" so the computer can minimize \"badness\" (just like in OLS). \n\n:::\n\n## MLE Versions {.fsmaller}\n\n- [Full Maximum Likelihood]{.b .blue} (ML) includes both the regression<br />coefficients and the variance components in the likelihood\n    + &#9989; Can compare models with different (fixed) predictors\n    + &#10060; Variance component estimates may be too small (biased)\n\n:::{.fragment}\n- [Restricted Maximum Likelihood]{.b .green} (REML) only includes the<br>  variance components in the likelihood and then estimates the<br> regression coefficients in a separate step\n    + &#9989; Corrects the bias in the variance components\n    + &#10060; Can't compare models with different (fixed) predictors\n    \n:::\n\n## Practical Advice: ML vs REML\n\n- **When reporting parameters:**\n    + Use [REML]{.b .green} (default in most software)\n    + It gives less biased estimates of variance/SD\n\n:::{.fragment}\n- **When comparing models:**\n    + If models differ in (fixed) predictors, use [ML]{.b .blue}\n    + If models differ only in cluster structure, use [REML]{.b .green}\n\n:::\n\n## How to optimize it? {.fsmaller}\n\n- Unlike OLS, there is no **closed-form solution**\n    + We cannot simply solve for the answer with algebra\n    + (The math is too complex to do in one step)\n\n:::{.fragment}\n- Instead, we must use an [iterative search]{.b .blue}\n    + We try a value, check the fit, and improve it\n    + We repeat this loop until the answer stops changing\n\n:::\n\n:::{.fragment}\n- We often use [local derivatives]{.b .green} to guide the search\n    + **Gradient:** Which direction is steepest? *(The Compass)*\n    + **Hessian:** How curved is the hill? *(The Map)*\n    + *Note: If the terrain is flat or ambiguous, the search may fail*\n\n:::\n\n## Hill Climbing Analogy {.fsmaller}\n\na. I am blindfolded in a thick fog and dropped on a hill\nb. I can win a great prize if I find the summit without looking\nc. Luckily, I have a device that announces my elevation\n\n:::{.fragment}\nd. I step in a random direction and then check my elevation\n    + If it increased, then I step again in that direction\n    + If it decreased, I step back and try another direction\n\n:::\n:::{.fragment}\ne. I repeat (d) until stepping in any direction decreases my elevation\n    + I am now at a peak of the hill (and hopefully the summit)\n    \n:::\n\n## Hill Climbing Challenges {.fsmaller}\n\n- What if I walk for days and never reach a peak of the hill?\n\n- What if I get stuck on a local peak that isn't the summit?\n\n:::{.fragment}\n**Potential Solutions**\n\n- I can map out the curvature around me (before taking each step)\n    + *This may prevent me from committing to unfruitful paths*\n\n:::\n:::{.fragment}\n- I can partner with other hill climbers (and share the prize money)\n    + *With different starting places, some may avoid local peaks*\n    + *With different step sizes, some may find additional paths*\n    \n:::\n\n## Optimization as Hill Climbing {.fsmaller}\n\na. Select a random or \"best guess\" starting value^[We can optionally use a \"multi-start\" strategy (for multiple climbers)]\nb. Estimate the likelihood of the current value^[Technically, we try to minimize the negative log-likelihood]\nc. Detemine whether to increase or decrease the value^[We can optionally use derivative information (gradient/hessian) here]\nd. Update the current value by some amount (step size)^[We can adjust the step size, which affects speed and pathing]\ne. Repeat steps 2-4 until the change in likelihood is small^[We repeat until convergence or a maximum number of iterations]\n\n\n## Visual Example\n\nWe start with no knowledge of the likelihood function\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n## Visual Example 2\n\nWe can choose three starting values at $x=\\{0,5,10\\}$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n## Visual Example 2\n\nNow each climbs until convergence and the highest wins\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n:::{.footer}\nOur maximum likelihood estimate would thus be $x \\approx 2$\n\n:::\n\n## Visual Example 3\n\nThe *unknown-to-us* likelihood function is plotted in black\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n## Optimization Algorithms {.fsmaller}\n\n- **Quadratic Approximation** (lme4) \n    + Does not require derivative information (Gradient/Hessian)\n    + &#9989; High speed, good when derivatives are difficult to compute\n    + &#10060; Struggles with complex models, many warnings\n\n:::{.fragment}\n- **Quasi-Newton** (glmmTMB) \n    + Uses derivative information (Gradient/Hessian)\n    + &#9989; Manages parameters boundaries, fewer warnings\n    + &#10060; Sensitive to starting values, slower speed\n\n:::\n:::{.fragment}\n- ***Expectation Maximization (EM)*** has benefits for missing data\n\n:::\n\n\n# Bayesian Alternative\n\n## Overview\n\n- MLE only uses the Likelihood for estimation\n    + It relies entirely on the observed sample\n    + It is \"objective\" and purely data-driven\n    + But it can be misled by small samples\n\n:::{.fragment}\n- [Bayesian estimation]{.b .blue} also uses the Likelihood\n    + But it combines it with other information\n    + Specifically, it relies on the user to input a [prior]{.b .green}\n    \n:::\n\n## Bayes' Theorem\n\n1. Prior = Information from Before Seeing Data\n2. Likelihood = Information from Observed Sample\n3. Posterior = Updated or Combined Information\n\n$$\n\\text{Posterior} \\propto \\frac{\\text{Likelihood}\\cdot\\text{Prior}}{\\text{Marginal Likelihood}} \\\\\n$$\n\n:::{.fragment}\n\n$$\nP(\\theta|\\text{Data}) \\propto \\frac{P(\\text{Data}|\\theta)P(\\theta)}{P(\\text{Data})}\n$$\n\n:::\n\n## Visual Depiction: Prior\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n## Visual Depiction: Likelihood\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n## Visual Depiction: Posterior\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n## Comparison\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n## Informative Priors\n\n- An [informative]{.b .blue} prior: *specific values are more likely*\n    + This can stabilize estimates in small samples\n    + But can be misleading and needs to be justified\n    \n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-12-1.png){width=1152}\n:::\n:::\n\n\n\n## Noninformative Priors\n\n- A [noninformative]{.b .blue} prior: *all values are equally likely*\n    + This can yield estimates very similar to MLE\n    + But some values are really implausible...\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-13-1.png){width=1152}\n:::\n:::\n\n\n## Weakly Informative Priors\n\n- A [weakly informative]{.b .blue} prior: *plausible values are more likely*\n    + We can discourage the model from implausible values\n    + We can conservatively center it on the null value\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-14-1.png){width=1152}\n:::\n:::\n\n\n## Approximating the Posterior\n\n- Bayes' theorem requires estimating the Marginal Likelihood\n    + In most situations, solving for this would be impossible\n\n:::{.fragment}  \n- Instead, we usually try to approximate the posterior\n    + We use Markov Chain Monte Carlo (MCMC) to do so\n    + This is an iterative procedure that can be intensive\n    + It provides a distribution of samples from the posterior\n    \n:::\n\n## Estimation Comparisons {.fsmaller}\n\n- [Maximum Likelihood Estimation]{.b .blue}\n    + **Goal:** Find the single best Frequentist estimate (the peak)\n    + **Method:** \"Climb the hill\" using local derivatives\n    + **Pros/Cons:** Faster, but gets stuck on flat or complex terrain\n\n:::{.fragment}\n- [Markov Chain Monte Carlo]{.b .green}\n    + **Goal:** Approximate the entire Bayesian posterior (the shape)\n    + **Method:** \"Explore the mountain\" using random sampling\n    + **Pros/Cons:** Slower, but more robust (less likely to fail)\n\n:::\n\n## Using the Posterior {.fsmaller}\n\n::: {.columns .pv4}\n\n::: {.column width=\"50%\"}\n**1. Point Estimate**<br>\nWe report the center of the posterior distribution (e.g., the [Median]{.b .red}) as our single \"best guess\" for the parameter.\n:::\n\n::: {.column width=\"50%\"}\n**2. Uncertainty Interval**<br>\nWe report the interval containing the inner 95% of the posterior density (e.g., the [HDI]{.b .red}) to show our uncertainty.\n:::\n\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](a_Slides_files/figure-revealjs/unnamed-chunk-15-1.png){width=1152}\n:::\n:::\n\n",
    "supporting": [
      "a_Slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}