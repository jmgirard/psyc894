{
  "hash": "7bb528f55422433ac91de8b19821c86a",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat: \n  revealjs:\n    css: ../../styles.css\n    slide-number: true\n    show-slide-number: all\n    preview-links: false\n    progress: true\n    history: true\n    hash-type: number\n    theme: default\n    code-block-background: true\n    highlight-style: zenburn\n    code-link: false\n    code-copy: true\n    code-line-numbers: false\n    controls: true\n    pagetitle: \"Multilevel Modeling\"\n    author-meta: \"Jeffrey Girard\"\n    semester: \"Spring 2026\"\n    course: \"PSYC 894\"\n    lecture: \"03a\"\nexecute:\n  echo: true\n  eval: true\n  collapse: false\n  cache: false\n---\n\n::: {.my-title}\n# [Multilevel Modeling]{.blue}\nIssues with Clustered Data\n\n::: {.my-grey}\n[{{< meta semester >}} | CLAS | {{< meta course >}}]{}<br />\n[Jeffrey M. Girard | Lecture {{< meta lecture >}}]{}\n:::\n\n![](../../img/city-girl.svg){.absolute bottom=30 right=0 width=\"400\"}\n:::\n\n## Roadmap\n\n::: {.columns .pv4}\n\n::: {.column width=\"60%\"}\n1. Multilevel Data and Questions\n  \n2. Conceptual Issues with Clustering\n\n3. Statistical Issues with Clustering\n:::\n\n::: {.column .tc .pv4 width=\"40%\"}\n{{< lif \"../../icons/map.json\" trigger=hover colors=secondary:#2a76dd class=rc >}}\n:::\n\n:::\n\n\n# Multilevel Data and Multilevel Questions\n\n## What is multilevel data? {.smaller}\n\n- Data are [hierarchically clustered]{.b .blue} when there are groups of observations<br> that are more similar *within* groups than they are *between* groups\n    + We say that observations are **nested within** clusters\n    + We count the levels (L\\#) in ascending order of nesting\n    + *e.g., students (L1) within classrooms (L2)... within schools (L3)...*\n    + *e.g., days (L1) within participants (L2)... within countries (L3)...*\n\n::: {.fragment}\n- In MLM, we assume a [successive sampling]{.b .green} strategy\n    + Specifically, we randomly sample from the top-down\n    + *e.g., we sample classrooms and then students within each classroom*\n    + *e.g., we sample participants and then days within each participant*\n\n:::\n\n## What is and isn't a cluster? {.smaller}\n\n::: {.columns}\n::: {.column width=\"50%\"}\n[Random Clusters...]{.b .blue}\n\n- Are **randomly sampled**\n- Come from a **population**\n- Are **interchangeable**\n- Are not exhaustive\n- Permit **generalization**\n- Require a **large number**\n\n:::{.fragment}\n- *e.g., classrooms*\n- *e.g., individuals*\n\n:::\n:::\n::: {.column width=\"50%\"}\n\n[Fixed Groups...]{.b .green}\n\n- Are not randomly sampled\n- Do not come from a population\n- Are not interchangeable\n- Are (typically) **exhaustive**\n- Do not permit generalization\n- Do not require a large number\n\n::: {.fragment}\n- *e.g., biological sexes*\n- *e.g., experimental conditions*\n:::\n:::\n:::\n\n## Types of Multilevel Variables {.smaller}\n\n- [Global]{.b .blue} variables describe their own level\n    + *e.g., the **motivation** of a student (L1) or the **size** of a class (L2)*\n    + *e.g., the **stress level** of a day (L1) or the **gender** of a participant (L2)*\n\n::: {.fragment}\n- [Structural]{.b .green} variables \"aggregate up\" from a lower-level\n    + *e.g., the **average motivation** of a class (L2), aggregated up from students (L1)*\n    + *e.g., the **average stress level** of a participant (L2), aggregated up from days (L1)*\n\n:::\n\n::: {.fragment}\n- [Contextual]{.b .red} variables \"disaggregate down\" from a higher-level\n    + *e.g., the **classroom size** of a student (L1), disaggregated down from class (L2)*\n    + *e.g., the **gender** of a day (L1), disaggregated down from participant (L2)*\n\n:::\n\n\n\n## Multilevel Research Questions {.smaller}\n\n- [Within-Cluster]{.b .blue} Questions\n    + *e.g., how does student motivation (L1) relate to student achievement (L1)?*\n    + *e.g., how does daily stress (L1) relate to daily calorie intake (L1)?*\n\n:::{.fragment}\n- [Between-Cluster]{.b .green} Questions\n    + *e.g., how does average motivation (L2) relate to average achievement (L2)?*\n    + *e.g., how does participant gender (L2) relate to average calorie intake (L2)?*\n\n:::\n\n:::{.fragment}\n- [Cross-level]{.b .red} Questions\n    + *e.g., does the relationship between a student's motivation (L1) and achievement (L1) depend on the class's average motivation (L2)?*\n    + *e.g., does the relationship between daily stress (L1) and daily calorie intake (L1) depend on the participant's gender (L2)?*\n\n:::\n\n\n## Brief Activity\n\n1. How might data you care about be **clustered**? \n    + *What are the clusters, levels, and level numbers?*\n\n:::{.fragment}\n2. What are some **multilevel variables** you care about?\n    + *What level is each variable on? What type is each?*\n    \n:::\n\n:::{.fragment}\n3. What are some **multilevel questions** you care about?\n    + *Is each within-cluster, between-cluster, or cross-level?*\n    \n:::\n\n\n# Conceptual Issues\n\n## Simpson's Paradox\n\n> Individuals who engage in more rigorous physical activity generally have a *lower* average resting heart rate. However, in the moment, engaging in more rigorous physical activity temporarily *increases* heart rate.\n\n:::{.callout-important title=\"Caution\" .fragment .pv4}\n- Relationships may actually reverse at different levels\n:::\n\n## The Ecological Fallacy\n\n> Wealthier countries tend to have *higher* average happiness levels. However, this does not necessarily imply that, within a given country, wealthier individuals tend to be happier. In fact, this effect tends to be much *weaker.*\n\n:::{.callout-important title=\"Caution\" .fragment}\n- Higher-level results may not apply to lower levels\n:::\n\n## The Atomistic Fallacy\n\n> Wealthier individuals in the USA tend to vote more conservatively. However, this does not necessarily imply that wealthier regions also tend to vote more conservatively. In fact, the opposite is true with US states and counties tending to vote more liberally.\n\n:::{.callout-important title=\"Caution\" .fragment}\n- Lower-level results may not apply to higher levels\n:::\n\n## Lurking Moderators\n\n> A new treatment may work (or not work) in a given hospital. However, this does not necessarily imply that it would also work (or not work) in all hospitals. There may be other hospital-level moderators at play (e.g., due to different staff, patients, and environmental factors).\n\n:::{.callout-important title=\"Caution\" .fragment}\n- A lower-level effect may only be present in certain clusters\n:::\n\n# Statistical Issues\n\n## Forcing a Single Level {.smaller}\n\n- If we [disaggregate to the lowest level]{.b .blue} and run a single-level model...\n    + We treat 10 students in 20 classrooms as 200 IID students\n    + Standard errors will be too low and power will be too high\n    + We will increase our Type I Error rate (false positives)\n    + We may commit the atomistic fallacy (if actually interested in L2)\n\n:::{.fragment}\n- If we [aggregate to the highest level]{.b .green} and run a single-level model...\n    + We treat 10 students in 20 classrooms as 20 IID classrooms\n    + Standard errors will be okay but power will be too low\n    + We will increase our Type II Error rate (false negatives)\n    + We may commit the ecological fallacy (if actually interested in L1)\n    \n:::\n\n:::{.fragment}\n- In neither case can we explore [cross-level research questions]{.b .red}\n\n:::\n\n## Why is the SE too low? {.smaller}\n\n- If we disaggregate to the lowest level, $N$ will be too high\n    + We are pretending that we have 200 IID observations\n    + But if observations from the same cluster are identical...\n    + ...then we really only have 20 unique observations\n    + We are taking credit for unique data we don't have\n    + This will give us too much confidence (SEs will be too low)\n    \n:::{.fragment}\n- In reality, observations are rarely *identical* within clusters\n    + Clustering is rarely perfect, but it likely has *some* influence\n    + Our [effective sample size]{.b .blue} is somewhere between 20 and 200\n    + Our standard errors should thus be increased by some factor\n\n:::\n\n\n## Why does getting N right matter?\n\n$$\nSE_{\\beta_p}=\\frac{SD_Y}{SD_{X_p}} \\sqrt{\\frac{1-R^2}{(n-k-1)(1-R_p^2)}}\n$$\n\n:::{.tc .f1}\n$n$ is the sample size (assuming IID)<br>\n$k$ is the number of predictor ($X$) variables<br>\n$R^2$ is the variance in $Y$ explained by all $X$<br>\n$R_p^2$ is the variance in $X_p$ explained by all other $X$\n\n:::\n\n:::{.callout-important title=\"Warning\" .fragment}\nIf $n$ is too large, then $SE_{\\beta_p}$ will be too small.\n:::\n\n## The Intraclass Correlation (ICC)\n\n- How strong is the clustering or interdependency?\n- How correlated are observations from the same cluster?\n\n$$\nICC = \\rho = \\frac{\\sigma^2_{between}}{\\sigma^2_{between}+\\sigma^2_{within}} = \\frac{\\tau_{00}^2}{\\tau_{00}^2+\\sigma^2}\n$$\n\n- Is there homogeneity within clusters (relatively low $\\sigma^2$)?\n- Is there heterogeneity between clusters (relatively high $\\tau_{00}^2$)?\n- Ranges from 0 (no clustering) to 1 (perfect clustering)\n\n\n## Design Effect\n\n- The [design effect]{.b .blue} (DEFF) is a ratio of the sampling variability observed to that expected from a simple random sample\n\n$$\nDEFF=1+\\rho(\\bar{n}_j - 1)\n$$\n\n:::{.tc}\nwhere $\\rho$ is the ICC and $\\bar{n}_j$ is the average cluster size\n:::\n\n- The square root of the design effect (DEFT) is what you need to multiply $SE_{\\beta}$ by to *roughly* correct it for clustering bias^[We will learn some more accurate corrections next lecture.]\n\n## Effective Sample Size\n\nThe design effect (DEFF) can also be used to calculate the [effective sample size]{.b .blue} $(n^*)$ accounting for clustering\n\n$$\nn^*=\\frac{n}{1+\\rho(\\bar{n}_j - 1)}\n$$\n\n:::{.callout-note title=\"Implications\"}\n- Higher ICC $(\\rho)$ reduces effective sample size (more bias)\n- Higher cluster size reduces effective sample size (more bias)\n:::\n\n## Brief Activity {.fsmaller}\n\nI collect data from 30 participants and each participant completes between 200 and 400 trials (M=301.2) of a behavioral experiment. I ran a linear regression and my hypothesized effect was significant! However, my annoying friend told me that I am ignoring \"clustering\" or something and that my effect might not be significant after all. My other, nice friend showed me how to calculate the ICC and said it looked pretty low. So things are fine with my analysis... right?\n\nCalculate the ICC, DEFF, DEFT, and $n^*$ given that my estimates are that the between-participant variance was 1.23 and the within-participant variance was 20.98. Then answer my question.\n\n## Answer Key\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(icc <- 1.23 / (1.23 + 20.98))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.05538046\n```\n\n\n:::\n:::\n\n\n:::{}\n\n::: {.cell}\n\n```{.r .cell-code}\n(deff <- 1 + icc * (301.2 - 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 17.62521\n```\n\n\n:::\n:::\n\n:::\n\n:::{}\n\n::: {.cell}\n\n```{.r .cell-code}\n(deft <- sqrt(deff))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.198239\n```\n\n\n:::\n:::\n\n:::\n\n:::{}\n\n::: {.cell}\n\n```{.r .cell-code}\n(neff <- (30 * 301.2) / deff)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 512.6746\n```\n\n\n:::\n:::\n\n:::\n\n:::{}\nAlthough the ICC is only 0.055, which seems small, the average cluster size is quite large at 301.2. Because both matter, the SEs are around 4 times too small. That's likely a big problem!\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}